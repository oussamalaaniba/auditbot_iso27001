# --- Imports ---
import os
from pathlib import Path
from io import BytesIO
import io
from typing import Optional, Dict, List, Tuple

import streamlit as st
import pandas as pd
import plotly.express as px
import fitz  # PyMuPDF
import docx
import json
from dotenv import load_dotenv
from openai import OpenAI
import base64
import hashlib
import re
from datetime import datetime

# Optional dependencies (safe fallbacks if missing)
try:
    import openpyxl  # for Excel styling
    OPENPYXL_AVAILABLE = True
except Exception:
    OPENPYXL_AVAILABLE = False

# ISO 27001 (existant)
from core.questions import ISO_QUESTIONS_INTERNE, ISO_QUESTIONS_MANAGEMENT
from core.analysis import (
    analyse_responses,
    save_gap_analysis,
    generate_action_plan_from_ai,
    save_action_plan_to_excel
)
from core.report import generate_audit_report

# ANSSI (nouveau)
from core.anssi_hygiene import ANSSI_SECTIONS, flatten_measures, STATUSES, SCORE_MAP

# (Optionnel) RAG utils si pr√©sents
try:
    from utils.ai_helper import build_vector_index, propose_anssi_answer  # RAG avanc√©
    RAG_AVAILABLE = True
except Exception:
    RAG_AVAILABLE = False

# --- Config & constantes ---
st.set_page_config(page_title="Audit Assistant (ISO 27001 ‚Ä¢ ANSSI)", layout="wide")

BASE_DIR = Path(__file__).resolve().parent
OUTPUT_DIR = BASE_DIR / "data" / "output"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# =========================================================
#   Fond d'√©cran (optionnel)
# =========================================================
def add_bg_from_local(image_file: str):
    try:
        with open(image_file, "rb") as f:
            data = f.read()
        encoded = base64.b64encode(data).decode()
        st.markdown(
            f"""
            <style>
            .stApp {{
                background-image: url("data:image/png;base64,{encoded}");
                background-size: cover;
                background-position: center;
                background-repeat: no-repeat;
                background-attachment: fixed;
            }}
            </style>
            """,
            unsafe_allow_html=True
        )
    except Exception:
        pass

if (BASE_DIR / "bg.png").exists():
    add_bg_from_local(str(BASE_DIR / "bg.png"))

st.markdown("""
<style>
/* Forcer les titres √† rester blancs dans toute l'app */
html[data-theme="light"] .stApp h1,
html[data-theme="dark"]  .stApp h1,
html[data-theme="light"] .stApp h2,
html[data-theme="dark"]  .stApp h2,
html[data-theme="light"] .stApp h3,
html[data-theme="dark"]  .stApp h3,
html[data-theme="light"] .stApp h4,
html[data-theme="dark"]  .stApp h4 {
  color: #ffffff !important;
  text-shadow: 0 2px 6px rgba(0,0,0,0.45); /* am√©liore la lisibilit√© sur fonds clairs ou fonc√©s */
}
</style>
""", unsafe_allow_html=True)


# =========================================================
#   OpenAI helpers
# =========================================================
def get_openai_api_key() -> Optional[str]:
    try: load_dotenv()
    except Exception: pass
    key = os.getenv("OPENAI_API_KEY")
    if key: return key
    try: return st.secrets["OPENAI_API_KEY"]
    except Exception: return None

def get_openai_client() -> Optional[OpenAI]:
    key = get_openai_api_key()
    if not key: return None
    try: return OpenAI(api_key=key)
    except Exception: return None

# =========================================================
#   Uploader GLOBAL (persistant + r√©utilisable partout)
# =========================================================
def _init_uploaded_docs_state():
    st.session_state.setdefault("uploaded_docs", [])  # [{name, bytes, size, sha1}]

def _file_sha1(b: bytes) -> str:
    return hashlib.sha1(b).hexdigest()

def _extract_text_from_pdf_bytes(b: bytes) -> str:
    try:
        pdf = fitz.open(stream=b, filetype="pdf")
        return "\n".join([p.get_text("text") for p in pdf])
    except Exception:
        return ""

def _extract_text_from_docx_bytes(b: bytes) -> str:
    try:
        d = docx.Document(io.BytesIO(b))
        return "\n".join(p.text for p in d.paragraphs if p.text)
    except Exception:
        return ""

def render_global_uploader():
    """Affiche un uploader r√©utilisable sur toutes les pages/onglets.
    Les fichiers sont m√©moris√©s et r√©utilisables pour l'IA/RAG."""
    _init_uploaded_docs_state()
    with st.expander("üìé Documents d'appui (uploader global) ‚Äî visibles partout", expanded=True):
        new_files = st.file_uploader(
            "Ajouter des documents (PDF/DOCX/TXT/PNG/JPG) pour enrichir l'analyse (RAG)",
            type=["pdf", "docx", "txt", "png", "jpg", "jpeg"],
            accept_multiple_files=True,
            key="global_uploader",
            help="Les documents ajout√©s ici restent disponibles sur toutes les pages."
        )
        if new_files:
            added = 0
            for f in new_files:
                data = f.read()
                sig = _file_sha1(data)
                if not any(item.get("sha1") == sig for item in st.session_state["uploaded_docs"]):
                    st.session_state["uploaded_docs"].append({
                        "name": f.name,
                        "bytes": data,
                        "size": len(data),
                        "sha1": sig,
                    })
                    added += 1
            if added:
                st.success(f"{added} document(s) ajout√©(s).")

        if st.session_state["uploaded_docs"]:
            st.caption("Documents m√©moris√©s :")
            for i, item in enumerate(st.session_state["uploaded_docs"], start=1):
                col1, col2, col3 = st.columns([6, 2, 2])
                with col1:
                    st.write(f"{i}. **{item['name']}** ‚Äî {round(item['size']/1024, 1)} KB")
                with col2:
                    st.download_button(
                        "T√©l√©charger",
                        data=item["bytes"],
                        file_name=item["name"],
                        key=f"dl_{item['sha1']}"
                    )
                with col3:
                    if st.button("Retirer", key=f"rm_{item['sha1']}"):
                        st.session_state["uploaded_docs"] = [
                            x for x in st.session_state["uploaded_docs"] if x["sha1"] != item["sha1"]
                        ]
                        st.rerun()

def get_uploaded_docs_bytes() -> List[Tuple[str, bytes]]:
    _init_uploaded_docs_state()
    return [(x["name"], x["bytes"]) for x in st.session_state["uploaded_docs"]]

def get_uploaded_docs_text(truncate: int = 16000) -> str:
    """Concat√®ne le texte des documents upload√©s (PDF/DOCX/TXT)."""
    _init_uploaded_docs_state()
    texts: List[str] = []
    for item in st.session_state["uploaded_docs"]:
        name = item["name"].lower()
        b = item["bytes"]
        if name.endswith(".pdf"):
            texts.append(_extract_text_from_pdf_bytes(b))
        elif name.endswith(".docx"):
            texts.append(_extract_text_from_docx_bytes(b))
        elif name.endswith(".txt"):
            try:
                texts.append(b.decode("utf-8", errors="ignore"))
            except Exception:
                pass
    return ("\n\n".join(texts))[:truncate]

# =========================================================
#   Nettoyage IA (no JSON rendu) + parsing statut
# =========================================================
def ensure_plain_text(s: str) -> str:
    """Supprime fences ```...``` et convertit un √©ventuel JSON simple en texte clair FR."""
    if not isinstance(s, str):
        return str(s)
    s2 = re.sub(r"```(?:json|JSON)?\s*", "", s)
    s2 = s2.replace("```", "").strip()
    # tenter JSON -> texte
    try:
        obj = json.loads(s2)
        parts: List[str] = []
        if isinstance(obj, dict):
            if "status" in obj: parts.append(f"**Statut** : {obj['status']}")
            if "justification" in obj and obj.get("justification"):
                parts.append(f"**Justification** : {obj['justification']}")
            if "recommandations" in obj and isinstance(obj["recommandations"], list):
                parts.append("**Recommandations :**\n- " + "\n- ".join(map(str, obj["recommandations"])))
            if "actions_top3" in obj and isinstance(obj["actions_top3"], list):
                parts.append("**Actions prioritaires :**\n- " + "\n- ".join(map(str, obj["actions_top3"])))
            if not parts:
                for k, v in obj.items():
                    if isinstance(v, list):
                        parts.append(f"{k} :\n- " + "\n- ".join(map(str, v)))
                    else:
                        parts.append(f"{k} : {v}")
            return "\n\n".join(parts)
        if isinstance(obj, list):
            lines: List[str] = []
            for it in obj:
                if isinstance(it, dict):
                    line = ", ".join([f"{k}={v}" for k, v in it.items()])
                    lines.append(f"- {line}")
                else:
                    lines.append(f"- {it}")
            return "\n".join(lines)
    except Exception:
        pass
    return s2

def parse_status_from_text(txt: str) -> Optional[str]:
    """
    D√©tecte un statut dans du texte libre.
    G√®re : Conforme, Partiellement conforme, Non conforme, Pas r√©ponse, NA (Not Applicable).
    """
    if not isinstance(txt, str):
        return None
    t = txt.lower()

    # expressions courantes pour NA
    if any(kw in t for kw in [
        "not applicable", "n/a", "n.a", "na)", "(na", "na ", " non applicable", " hors p√©rim√®tre", " hors perimetre"
    ]):
        return "NA"

    for s in ["Conforme", "Partiellement conforme", "Non conforme", "Pas r√©ponse", "NA"]:
        if s.lower() in t:
            return s

    m = re.search(
        r"(statut|status)\s*[:\-]\s*(conforme|partiellement conforme|non conforme|pas r√©ponse|na|n\/a|not applicable)",
        t
    )
    if m:
        val = m.group(2).strip()
        if val in ["na", "n/a", "not applicable"]:
            return "NA"
        for s in ["Conforme", "Partiellement conforme", "Non conforme", "Pas r√©ponse"]:
            if s.lower() == val:
                return s
    return None

# =========================================================
#   Statuts & scoring (ajout NA)
# =========================================================
# Assure que NA est pr√©sent m√™me si le module core n‚Äô√©tait pas √† jour
if "NA" not in STATUSES:
    try:
        STATUSES.append("NA")
    except Exception:
        pass

STATUS_META = {
    "Conforme": {"score": 1.00, "emoji": "‚úÖ", "priority": "Low"},
    "Partiellement conforme": {"score": 0.50, "emoji": "üü°", "priority": "Medium"},
    "Non conforme": {"score": 0.00, "emoji": "‚ùå", "priority": "High"},
    "Pas r√©ponse": {"score": 0.25, "emoji": "‚ö™", "priority": "Medium"},
    "NA": {"score": None, "emoji": "üö´", "priority": "N/A"},
}

# =========================================================
#   Helpers ANSSI : DataFrames + Exports + Rapport DOCX
# =========================================================
def _anssi_build_dataframe(measures, status_map: Dict[str, str], justifs_map: Dict[str, str]) -> pd.DataFrame:
    rows = []
    for m in measures:
        mid = m["id"]; theme = m["theme"]; title = m["title"]
        stt = status_map.get(mid, "Pas r√©ponse")
        meta = STATUS_META.get(stt, STATUS_META["Pas r√©ponse"])
        score = meta["score"]
        rows.append({
            "Th√®me": theme,
            "ID": mid,
            "Mesure": title,
            "Statut": stt,
            "Emoji": meta["emoji"],
            "Score (%)": int(round(score*100)) if isinstance(score, (int, float)) else None,
            "Priorit√©": meta["priority"],
            "Justification": ensure_plain_text(justifs_map.get(mid, "")),
        })
    order = ["Th√®me", "ID", "Mesure", "Statut", "Emoji", "Score (%)", "Priorit√©", "Justification"]
    return pd.DataFrame(rows)[order].sort_values(["Th√®me","ID"]).reset_index(drop=True)

def _anssi_theme_maturity(df: pd.DataFrame) -> pd.DataFrame:
    use = df[df["Score (%)"].notnull()]
    if use.empty:
        return pd.DataFrame(columns=["Th√®me","Maturit√© moyenne (%)"])
    g = use.groupby("Th√®me")["Score (%)"].mean().round(1).reset_index()
    g.columns = ["Th√®me", "Maturit√© moyenne (%)"]
    return g.sort_values("Maturit√© moyenne (%)", ascending=False)

def _save_csv_pretty(df: pd.DataFrame, path: Path) -> None:
    df_csv = df.copy()
    df_csv["Score (%)"] = df_csv["Score (%)"].fillna("")
    path.write_bytes(df_csv.to_csv(index=False).encode("utf-8"))

def _save_excel_styled(df: pd.DataFrame, theme_summary: pd.DataFrame, path: Path) -> None:
    with pd.ExcelWriter(path, engine="openpyxl" if OPENPYXL_AVAILABLE else None) as xw:
        df.to_excel(xw, sheet_name="R√©sultats d√©taill√©s", index=False)
        theme_summary.to_excel(xw, sheet_name="Synth√®se par th√®me", index=False)
        if not OPENPYXL_AVAILABLE:
            return
        wb = xw.book
        # R√©sultats d√©taill√©s
        ws = wb["R√©sultats d√©taill√©s"]
        widths = {"A":16, "B":10, "C":60, "D":20, "E":8, "F":11, "G":12, "H":80}
        for col, w in widths.items():
            ws.column_dimensions[col].width = w
        from openpyxl.styles import PatternFill, Font, Alignment
        head_fill = PatternFill(start_color="FFDADADA", end_color="FFDADADA", fill_type="solid")
        for cell in ws[1]:
            cell.fill = head_fill
            cell.font = Font(bold=True)
            cell.alignment = Alignment(wrap_text=True, vertical="top")
        color_map = {
            "Conforme": "FFC6EFCE",
            "Partiellement conforme": "FFFFF2CC",
            "Non conforme": "FFF8CBAD",
            "Pas r√©ponse": "FFD9D9D9",
            "NA": "FFCCE5FF",
        }
        for row in ws.iter_rows(min_row=2, min_col=1, max_col=ws.max_column):
            statut = row[3].value  # D
            fill = PatternFill(start_color=color_map.get(statut, "FFFFFFFF"),
                               end_color=color_map.get(statut, "FFFFFFFF"),
                               fill_type="solid")
            row[3].fill = fill
            # wrap text for Mesure & Justification
            row[2].alignment = Alignment(wrap_text=True, vertical="top")
            row[7].alignment = Alignment(wrap_text=True, vertical="top")
        # Synth√®se par th√®me
        ws2 = wb["Synth√®se par th√®me"]
        for cell in ws2[1]:
            cell.fill = head_fill
            cell.font = Font(bold=True)
        for col in ["A","B"]:
            ws2.column_dimensions[col].width = 30 if col=="A" else 22

def _save_action_plan_excel(actions_df: pd.DataFrame, path: Path) -> None:
    with pd.ExcelWriter(path, engine="openpyxl" if OPENPYXL_AVAILABLE else None) as xw:
        actions_df.to_excel(xw, sheet_name="Plan d'actions", index=False)
        if OPENPYXL_AVAILABLE:
            wb = xw.book
            ws = wb["Plan d'actions"]
            from openpyxl.styles import PatternFill, Font, Alignment
            for cell in ws[1]:
                cell.font = Font(bold=True)
            # widths
            widths = {"A":10,"B":12,"C":50,"D":12,"E":24,"F":30,"G":14,"H":12}
            for col, w in widths.items():
                ws.column_dimensions[col].width = w
            for row in ws.iter_rows(min_row=2, min_col=1, max_col=ws.max_column):
                row[2].alignment = Alignment(wrap_text=True, vertical="top")  # Action
                row[5].alignment = Alignment(wrap_text=True, vertical="top")  # Justification

def _save_anssi_report_docx(df: pd.DataFrame, theme_summary: pd.DataFrame,
                            actions_df: Optional[pd.DataFrame], path: Path,
                            org_meta: Dict[str, str]) -> None:
    """
    Rapport Word ANSSI structur√©, contenant TOUTES les r√©ponses d‚Äôaudit :
    - Couverture + Contexte
    - Executive Summary (KPI)
    - Synth√®se par th√®me
    - R√©sultats d√©taill√©s (toutes mesures) : ID, Mesure, Statut, Justification
    - (Optionnel) Plan d‚Äôactions
    """
    d = docx.Document()
    now = datetime.now().strftime("%Y-%m-%d")

    # --- Couverture
    d.add_heading("ANSSI Hygiene ‚Äì Assessment Report", 0)
    d.add_paragraph(f"Date: {now}")
    if org_meta:
        d.add_paragraph(
            f"Secteur: {org_meta.get('secteur','-')}  |  Employ√©s: {org_meta.get('nb_emp','-')}  |  Pays: {org_meta.get('pays','-')}"
        )

    # --- Executive Summary
    d.add_heading("Executive Summary", level=1)
    total = len(df)
    c = (df["Statut"] == "Conforme").sum()
    pc = (df["Statut"] == "Partiellement conforme").sum()
    nc = (df["Statut"] == "Non conforme").sum()
    na = (df["Statut"] == "Pas r√©ponse").sum()
    nna = (df["Statut"] == "NA").sum()
    valid = df["Score (%)"].dropna()
    overall = round(valid.mean(), 1) if not valid.empty else 0.0
    p = d.add_paragraph()
    p.add_run("Maturit√© globale: ").bold = True
    p.add_run(f"{overall}%")
    d.add_paragraph(f"R√©partition statuts: ‚úÖ {c} | üü° {pc} | ‚ùå {nc} | ‚ö™ {na} | üö´ {nna}")

    # --- Synth√®se par th√®me (table)
    d.add_heading("Synth√®se par th√®me", level=1)
    if not theme_summary.empty:
        t = d.add_table(rows=1, cols=2)
        hdr = t.rows[0].cells
        hdr[0].text = "Th√®me"
        hdr[1].text = "Maturit√© moyenne (%)"
        for _, r in theme_summary.iterrows():
            row = t.add_row().cells
            row[0].text = str(r["Th√®me"])
            row[1].text = str(r["Maturit√© moyenne (%)"])
    else:
        d.add_paragraph("Aucune mesure avec score (NA partout).")

    # --- R√©sultats d√©taill√©s par th√®me (TOUTES les r√©ponses)
    d.add_heading("R√©sultats d√©taill√©s", level=1)
    for theme, g in df.groupby("Th√®me"):
        d.add_heading(theme, level=2)
        # table avec toutes les mesures de ce th√®me
        tab = d.add_table(rows=1, cols=5)
        hdr = tab.rows[0].cells
        hdr[0].text = "ID"
        hdr[1].text = "Mesure"
        hdr[2].text = "Statut"
        hdr[3].text = "Score (%)"
        hdr[4].text = "Justification"
        for _, r in g.iterrows():
            row = tab.add_row().cells
            row[0].text = str(r["ID"])
            row[1].text = str(r["Mesure"])
            row[2].text = f"{r['Emoji']} {r['Statut']}"
            row[3].text = "" if pd.isna(r["Score (%)"]) else str(int(r["Score (%)"]))
            row[4].text = str(r["Justification"]) if r["Justification"] else "-"

    # --- Plan d‚Äôactions (optionnel)
    if actions_df is not None and not actions_df.empty:
        d.add_heading("Plan d‚Äôactions recommand√©", level=1)
        t = d.add_table(rows=1, cols=8)
        hdr = t.rows[0].cells
        hdr[0].text = "ID"
        hdr[1].text = "Th√®me"
        hdr[2].text = "Action"
        hdr[3].text = "Priorit√©"
        hdr[4].text = "Responsable"
        hdr[5].text = "Justification"
        hdr[6].text = "√âch√©ance"
        hdr[7].text = "Statut"
        for _, r in actions_df.iterrows():
            row = t.add_row().cells
            row[0].text = str(r["ID"])
            row[1].text = str(r["Th√®me"])
            row[2].text = str(r["Action"])
            row[3].text = str(r["Priorit√©"])
            row[4].text = str(r.get("Owner", ""))
            row[5].text = str(r.get("Justification", ""))
            row[6].text = str(r.get("√âch√©ance", ""))
            row[7].text = str(r.get("Suivi", "Ouvert"))
    d.save(path)

def _build_anssi_action_plan_df(df: pd.DataFrame) -> pd.DataFrame:
    """
    Construit un plan d‚Äôactions √† partir du DF des r√©sultats.
    Utilise l‚ÄôIA si possible pour produire des actions cibl√©es; sinon fallback g√©n√©rique.
    """
    # cibler d‚Äôabord Non conforme / Partiellement conforme
    target = df[df["Statut"].isin(["Non conforme", "Partiellement conforme"])].copy()
    if target.empty:
        return pd.DataFrame(columns=["ID","Th√®me","Action","Priorit√©","Owner","Justification","√âch√©ance","Suivi"])

    client = get_openai_client()
    actions: List[Dict[str, str]] = []

    if client is not None:
        # prompt group√© pour limiter les co√ªts
        items = []
        for _, r in target.iterrows():
            items.append({
                "id": r["ID"], "theme": r["Th√®me"],
                "mesure": r["Mesure"], "statut": r["Statut"],
                "justif": r["Justification"]
            })
        system = (
            "Tu es un consultant cybers√©curit√© senior. "
            "Pour chaque mesure fournie, propose 1 √† 2 actions concr√®tes, cibl√©es et prioris√©es. "
            "Format JSON strict: [{\"id\":\"...\",\"actions\":[\"...\",\"...\"],\"priorite\":\"High|Medium|Low\"}]"
        )
        user = "Mesures √† traiter:\n" + json.dumps(items, ensure_ascii=False)
        try:
            resp = client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                messages=[{"role":"system","content":system},{"role":"user","content":user}],
                temperature=0.2,
            )
            raw = (resp.choices[0].message.content or "").strip()
            data = json.loads(raw)
            # construire lignes
            for it in data:
                mid = it.get("id")
                prio = it.get("priorite","High")
                acts = it.get("actions") or []
                base = target[target["ID"] == mid]
                if base.empty:
                    continue
                theme = base.iloc[0]["Th√®me"]
                just = base.iloc[0]["Justification"]
                for a in acts[:2]:
                    actions.append({
                        "ID": mid, "Th√®me": theme, "Action": ensure_plain_text(a),
                        "Priorit√©": prio, "Owner": "", "Justification": ensure_plain_text(just),
                        "√âch√©ance": "", "Suivi": "Ouvert"
                    })
        except Exception:
            client = None  # fallback

    if client is None:
        # Fallback simple
        default_actions = {
            "Non conforme": "√âtablir un plan de rem√©diation document√©, d√©finir un owner et une √©ch√©ance; mettre en place le contr√¥le requis.",
            "Partiellement conforme": "Compl√©ter la documentation et √©tendre la couverture du contr√¥le; formaliser les preuves et indicateurs.",
        }
        for _, r in target.iterrows():
            actions.append({
                "ID": r["ID"], "Th√®me": r["Th√®me"], "Action": default_actions[r["Statut"]],
                "Priorit√©": "High" if r["Statut"] == "Non conforme" else "Medium",
                "Owner": "", "Justification": r["Justification"], "√âch√©ance": "", "Suivi": "Ouvert"
            })

    return pd.DataFrame(actions, columns=["ID","Th√®me","Action","Priorit√©","Owner","Justification","√âch√©ance","Suivi"])

# =========================================================
#                     ROUTER + HOME
# =========================================================
if "route" not in st.session_state:
    st.session_state["route"] = "home"

def go(route: str):
    st.session_state["route"] = route

def render_home():
    st.title("üß≠ Audit Assistant")
    st.caption("Centralisez vos audits, comparez vos pratiques, g√©n√©rez plans d‚Äôactions et rapports.")
    # Uploader global pr√©sent d√®s l'accueil
    render_global_uploader()
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ISO/IEC 27001")
        st.write("- Questionnaires (interne / pr√©-certif)\n- Gap Analysis + priorit√©s\n- Rapport pr√™t √† partager")
        st.button("‚ñ∂Ô∏è Entrer dans ISO 27001", key="home_go_iso", use_container_width=True, on_click=lambda: go("iso27001"))
    with col2:
        st.subheader("ANSSI ‚Äì Guide d‚Äôhygi√®ne")
        st.write("- Auto-√©valuation par th√®mes/mesures\n- Score de maturit√© & quick-wins\n- Exports pro (CSV/XLSX/DOCX)")
        st.button("‚ñ∂Ô∏è Entrer dans ANSSI Hygi√®ne", key="home_go_anssi", use_container_width=True, on_click=lambda: go("anssi_hygiene"))

# =========================================================
#                      ANSSI PAGE
# =========================================================
def render_anssi_hygiene():
    st.title("üõ°Ô∏è ANSSI ‚Äì Guide d‚Äôhygi√®ne")
    st.caption("Parcours : 1) Intro  ‚Ä¢  2) Questionnaire  ‚Ä¢  3) Revue  ‚Ä¢  4) R√©sultats")
    # Uploader global visible partout (exigence)
    render_global_uploader()

    # --- State init ---
    st.session_state.setdefault("anssi_stage", "intro")       # intro | questions | review | results
    st.session_state.setdefault("anssi_org", {})              # contexte entreprise
    st.session_state.setdefault("anssi_status", {})           # {id_mesure: statut}
    st.session_state.setdefault("anssi_justifs", {})          # {id_mesure: justification}
    st.session_state.setdefault("anssi_index", None)          # RAG index si dispo

    measures = flatten_measures()
    total = len(measures)

    def compute_progress():
        status_map = st.session_state["anssi_status"]
        answered = sum(1 for m in measures if status_map.get(m["id"]) in ("Conforme","Partiellement conforme","Non conforme","NA"))
        pct_answers = int(round(100 * answered / total)) if total else 0
        return pct_answers, answered

    def _index_docs():
        bins = get_uploaded_docs_bytes()
        if not bins:
            st.warning("Aucun document charg√© dans l‚Äôuploader global.")
            return
        if not RAG_AVAILABLE:
            st.info("Indexation avanc√©e indisponible (module RAG non import√©).")
            return

        class _UploadedLike:
            def __init__(self, name, data):
                self.name = name
                self._data = data
            def getvalue(self):
                return self._data

        files_like = [_UploadedLike(name, b) for name, b in bins]
        with st.spinner("Indexation et embeddings‚Ä¶"):
            st.session_state["anssi_index"] = build_vector_index(files_like)
        st.success("Index construit ‚úîÔ∏è")

    stage = st.session_state["anssi_stage"]

    # ---------- 1) INTRO ----------
    if stage == "intro":
        st.subheader("1) Informations de contexte")
        c1, c2 = st.columns(2)
        secteur = c1.text_input("Secteur d‚Äôactivit√©", st.session_state["anssi_org"].get("secteur",""), key="anssi_org_secteur")
        nb_emp   = c2.number_input("Nombre d‚Äôemploy√©s", min_value=1, value=int(st.session_state["anssi_org"].get("nb_emp", 100)), key="anssi_org_nbemp")
        ca       = c1.text_input("Chiffre d‚Äôaffaires (ex: 120 M‚Ç¨)", st.session_state["anssi_org"].get("ca",""), key="anssi_org_ca")
        pays     = c2.text_input("Filiales / Pays (ex: FR, LU, DE)", st.session_state["anssi_org"].get("pays",""), key="anssi_org_pays")
        st.info("Les documents d√©pos√©s via l‚Äôuploader global seront utilis√©s par l‚ÄôIA (RAG/texte).")

        colA, colB, colC = st.columns([1,1,1])
        if colA.button("üíæ Enregistrer & continuer", key="anssi_intro_save"):
            st.session_state["anssi_org"] = {"secteur": secteur, "nb_emp": nb_emp, "ca": ca, "pays": pays}
            st.session_state["anssi_stage"] = "questions"
            st.rerun()
        if colB.button("üß≠ Retour √† l‚Äôaccueil", key="anssi_intro_home"):
            go("home")
        colC.button("üß± Indexer les documents (IA avanc√©e)", key="anssi_index_btn_intro", on_click=_index_docs)
        return

    # ---------- IA: Pr√©remplissage global ----------
    def _anssi_autofill_from_global():
        client = get_openai_client()
        if client is None:
            st.warning("‚ÑπÔ∏è Pas de cl√© OpenAI ‚Äî pr√©remplissage IA d√©sactiv√©.")
            return

        org = st.session_state.get("anssi_org", {})

        # Si index RAG dispo + construit -> par mesure (qualit√© max)
        if RAG_AVAILABLE and st.session_state.get("anssi_index") and st.session_state["anssi_index"].get("chunks"):
            with st.spinner("Analyse IA (RAG) par mesure‚Ä¶"):
                for m in measures:
                    mid = m["id"]
                    requirement = m["title"]
                    question_md = _to_question_fr(requirement, m.get("theme"))
                    try:
                        res = propose_anssi_answer(requirement, question_md, st.session_state["anssi_index"])
                        status = res.get("status", "Pas r√©ponse")
                        if status not in STATUSES:
                            status = "Pas r√©ponse"
                        justif = ensure_plain_text(res.get("justification", ""))
                        cits = res.get("citations", [])
                        if cits:
                            justif = justif + "\n\n" + "Citations: " + "; ".join([f"{c['doc']} p.{c['page']}" for c in cits if isinstance(c, dict) and c.get('doc') and c.get('page')])
                        st.session_state["anssi_status"][mid] = status
                        st.session_state["anssi_justifs"][mid] = justif
                    except Exception:
                        st.session_state["anssi_status"][mid] = st.session_state["anssi_status"].get(mid, "Pas r√©ponse")
                st.success("‚úÖ Pr√©remplissage IA (RAG) termin√©.")
            return

        # Sinon: fallback via texte concat√©n√© des uploads (interne; JSON non affich√©)
        text = get_uploaded_docs_text()
        if not text:
            st.warning("‚ÑπÔ∏è Aucun document global charg√©. Ajoute des fichiers dans l‚Äôuploader global.")
            return

        measures_brief = [{"id": m["id"], "title": m["title"], "theme": m["theme"]} for m in measures]

        system_msg = (
            "Tu es un consultant cybers√©curit√© senior. "
            "√Ä partir du contexte d‚Äôentreprise et des extraits fournis, "
            "√©value chaque mesure ANSSI et propose un statut conservateur. "
            "Si l'information est insuffisante, r√©ponds 'Pas r√©ponse'. "
            "R√©ponds STRICTEMENT en JSON (liste d‚Äôobjets) : "
            "[{\"id\":\"...\",\"status\":\"Conforme|Partiellement conforme|Non conforme|Pas r√©ponse|NA\",\"justification\":\"...\",\"actions_top3\":[\"...\",\"...\",\"...\"]}]"
        )

        user_msg = f"""
Contexte organisation:
- Secteur: {org.get('secteur') or 'Inconnu'}
- Nb employ√©s: {org.get('nb_emp') or 'Inconnu'}
- CA: {org.get('ca') or 'Inconnu'}
- Pays/Filiales: {org.get('pays') or 'Inconnu'}

R√©f√©rentiel: ANSSI Guide d'hygi√®ne (10 th√®mes, ~42 mesures).
Mesures √† √©valuer (id/title/theme):
{json.dumps(measures_brief, ensure_ascii=False)}

Extraits de documents globaux (tronqu√©s):
{text}

Consignes:
- Donne un statut par mesure parmi: Conforme | Partiellement conforme | Non conforme | Pas r√©ponse | NA
- Justifie bri√®vement (2-4 lignes) + 3 actions prioritaires.
- Si incertain: 'Pas r√©ponse'.
Renvoie uniquement du JSON valide.
"""

        try:
            resp = client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                messages=[{"role": "system", "content": system_msg},
                          {"role": "user", "content": user_msg}],
                temperature=0.2,
            )
            raw = (resp.choices[0].message.content or "").strip()
            data = json.loads(raw)
        except Exception as e:
            st.error(f"Erreur IA: {e}")
            return

        for item in data:
            mid = item.get("id")
            status = item.get("status", "Pas r√©ponse")
            justif = item.get("justification", "")
            if not mid:
                continue
            if status not in STATUSES:
                status = "Pas r√©ponse"
            st.session_state["anssi_status"][mid] = status
            st.session_state["anssi_justifs"][mid] = ensure_plain_text(justif)

        st.success("‚úÖ Pr√©remplissage IA termin√© (fallback texte concat√©n√©).")

    # ---------- 2) QUESTIONNAIRE ----------
    if stage == "questions":
        pct_answers, answered = compute_progress()
        st.subheader("2) Questionnaire par th√©matiques")
        st.write(f"Avancement questionnaire : **{pct_answers}%** ‚Äî ({answered}/{total})")
        st.progress(pct_answers)

        # Actions IA utiles directement ici
        cA, cB, cC = st.columns([1,1,1])
        cA.button("üß† Pr√©remplir automatiquement (docs globaux)", key="anssi_autofill_btn", on_click=_anssi_autofill_from_global)
        cB.button("üß± (Re)Indexer documents (IA avanc√©e)", key="anssi_index_btn_q", on_click=_index_docs)
        cC.button("üè† Accueil", key="anssi_questions_home_btn", on_click=lambda: go("home"))

        theme = st.sidebar.radio("Th√®mes", list(ANSSI_SECTIONS.keys()), key="anssi_theme_radio")
        st.subheader(theme)

        SYSTEM_FRENCH_PLAIN = (
            "Tu es un auditeur s√©nior cybers√©curit√©/continuit√©. "
            "R√©ponds en fran√ßais, en texte clair (phrases ou puces). "
            "N'utilise aucun JSON, aucun code fence. "
            "Commence par une ligne 'Statut: ...' avec l'une des valeurs: "
            "Conforme, Partiellement conforme, Non conforme, Pas r√©ponse, NA. "
            "Puis donne une justification concise (3‚Äì6 lignes) et 2‚Äì4 actions concr√®tes."
        )

        for m in ANSSI_SECTIONS[theme]:
            mid = m["id"]
            requirement = m["title"]
            question_md = _to_question_fr(requirement, m.get("theme"))

            st.markdown(f"### {mid}")
            st.markdown(question_md)
            with st.expander("Voir l‚Äôexigence ANSSI (texte brut)"):
                st.write(requirement)

            # Statut (s√©lecteur)
            current = st.session_state["anssi_status"].get(mid, "Pas r√©ponse")
            new_status = st.selectbox(
                "Statut",
                STATUSES,
                index=STATUSES.index(current) if current in STATUSES else STATUSES.index("Pas r√©ponse"),
                key=f"status_{mid}"
            )
            st.session_state["anssi_status"][mid] = new_status

            # Zone texte consultant (r√©ponse d√©taill√©e)
            cur_just = st.session_state["anssi_justifs"].get(mid, "")
            new_just = st.text_area(
                "R√©ponse d√©taill√©e (consultant) ‚Äì Justification & √©l√©ments de preuve",
                value=cur_just,
                key=f"justif_{mid}",
                height=160,
                placeholder="R√©dige une justification professionnelle : politiques, journaux, tickets, preuves de tests, etc."
            )
            st.session_state["anssi_justifs"][mid] = new_just

            # IA par mesure (texte clair)
            cols = st.columns([1,1])
            if cols[0].button("üí° Proposer avec l‚ÄôIA", key=f"ai_{mid}"):
                client = get_openai_client()
                if client is None:
                    st.warning("Cl√© OpenAI manquante.")
                else:
                    try:
                        if RAG_AVAILABLE and st.session_state.get("anssi_index") and st.session_state["anssi_index"].get("chunks"):
                            # RAG ‚Üí formater en texte clair
                            res = propose_anssi_answer(requirement, question_md, st.session_state["anssi_index"])
                            status = res.get("status")
                            if status in STATUSES:
                                st.session_state["anssi_status"][mid] = status
                            justif = ensure_plain_text(res.get("justification", ""))
                            cits = res.get("citations", [])
                            if cits:
                                justif += "\n\nCitations: " + "; ".join([f"{c['doc']} p.{c['page']}" for c in cits if isinstance(c, dict) and c.get('doc') and c.get('page')])
                            st.session_state["anssi_justifs"][mid] = justif
                        else:
                            # Fallback: prompt texte clair (sans JSON)
                            context_text = get_uploaded_docs_text(truncate=8000)
                            user_prompt = (
                                f"EXIGENCE: {requirement}\n\nQUESTION:\n{question_md}\n\n"
                                f"CONTEXTE (extraits des documents, √©ventuellement vide):\n{context_text}\n\n"
                                "Donne uniquement du texte clair. Pas de JSON, pas de balises."
                            )
                            resp = client.chat_completions.create if hasattr(client, "chat_completions") else client.chat.completions.create
                            out = resp(
                                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                                messages=[
                                    {"role":"system","content": SYSTEM_FRENCH_PLAIN},
                                    {"role":"user","content": user_prompt}
                                ],
                                temperature=0.2
                            )
                            content = ensure_plain_text((out.choices[0].message.content or "").strip())
                            detected = parse_status_from_text(content) or "Pas r√©ponse"
                            if detected in STATUSES:
                                st.session_state["anssi_status"][mid] = detected
                            st.session_state["anssi_justifs"][mid] = content
                        st.success("Proposition IA appliqu√©e ‚úîÔ∏è")
                        st.rerun()
                    except Exception as e:
                        st.error(f"Erreur IA: {e}")

            cols[1].markdown("&nbsp;")
            st.divider()

        c1, c2, c3 = st.columns([1,1,1])
        c1.button("‚¨ÖÔ∏è Retour √† l‚Äôaccueil", key="anssi_questions_home", on_click=lambda: go("home"))
        c2.button("üîÑ Recalculer l‚Äôavancement", key="anssi_questions_recalc", on_click=st.rerun)
        if c3.button("‚û°Ô∏è Terminer le questionnaire", key="anssi_questions_next_review"):
            st.session_state["anssi_stage"] = "review"
            st.rerun()
        return

    # ---------- 2.5) REVIEW ----------
    if stage == "review":
        st.subheader("‚úîÔ∏è Revue avant analyse")
        pct_answers, answered = compute_progress()
        st.write(f"Avancement r√©ponses (hors 'Pas r√©ponse') : **{pct_answers}%** ‚Äî ({answered}/{total})")
        st.progress(pct_answers)

        missing = [m for m in measures if st.session_state["anssi_status"].get(m["id"], "Pas r√©ponse") == "Pas r√©ponse"]
        if missing:
            st.warning(f"Mesures sans r√©ponse : {len(missing)}")
            with st.expander("Voir les mesures sans r√©ponse"):
                for m in missing:
                    st.write(f"- {m['id']} ‚Äî {m['title']} ({m['theme']})")
        else:
            st.success("Toutes les mesures ont un statut (y compris 'NA' ou 'Pas r√©ponse').")

        c1, c2, c3 = st.columns([1,1,1])
        c1.button("‚¨ÖÔ∏è Retour au questionnaire", key="anssi_review_back_to_questions", on_click=lambda: st.session_state.update({"anssi_stage":"questions"}) or st.rerun())
        c2.button("üè† Accueil", key="anssi_review_home", on_click=lambda: go("home"))
        if c3.button("‚úÖ Valider & commencer l‚Äôanalyse (globale)", key="anssi_review_start"):
            st.session_state["anssi_stage"] = "results"
            st.rerun()
        return

    # ---------- 3) R√âSULTATS ----------
    if stage == "results":
        st.subheader("3) R√©sultats & Livrables")

        # DataFrames principaux
        df = _anssi_build_dataframe(measures, st.session_state["anssi_status"], st.session_state["anssi_justifs"])
        theme_summary = _anssi_theme_maturity(df)

        # Table interactive
        st.dataframe(df, use_container_width=True)

        # Charts rapides
        st.markdown("#### üìä R√©partition des statuts")
        counts = df["Statut"].value_counts().reset_index()
        counts.columns = ["Statut", "Nombre"]
        fig1 = px.pie(counts, values="Nombre", names="Statut", title="R√©partition des statuts")
        st.plotly_chart(fig1, use_container_width=True)

        st.markdown("#### üìà Maturit√© par th√®me")
        if not theme_summary.empty:
            fig2 = px.bar(theme_summary, x="Th√®me", y="Maturit√© moyenne (%)", title="Maturit√© moyenne par th√®me", text="Maturit√© moyenne (%)")
            st.plotly_chart(fig2, use_container_width=True)
        else:
            st.info("Aucune maturit√© calculable (scores NA seulement).")

        # Livrables
        csv_path = OUTPUT_DIR / "anssi_resultats.csv"
        xlsx_path = OUTPUT_DIR / "anssi_resultats.xlsx"
        plan_path = OUTPUT_DIR / "anssi_action_plan.xlsx"
        docx_path = OUTPUT_DIR / "anssi_rapport.docx"

        # Exports
        _save_csv_pretty(df, csv_path)
        _save_excel_styled(df, theme_summary, xlsx_path)

        # Plan d‚Äôactions (IA si possible)
        actions_df = _build_anssi_action_plan_df(df)
        if not actions_df.empty:
            _save_action_plan_excel(actions_df, plan_path)

        # Rapport DOCX (inclut TOUTES les r√©ponses d‚Äôaudit, bien structur√©es)
        _save_anssi_report_docx(df, theme_summary, actions_df if not actions_df.empty else None, docx_path, st.session_state.get("anssi_org", {}))

        # Boutons de t√©l√©chargement
        st.download_button("‚¨áÔ∏è Export CSV (propre)", data=open(csv_path, "rb").read(), file_name=csv_path.name, mime="text/csv")
        st.download_button("‚¨áÔ∏è Excel styl√© (r√©sultats + synth√®se)", data=open(xlsx_path, "rb").read(), file_name=xlsx_path.name)
        if not actions_df.empty:
            st.download_button("‚¨áÔ∏è Plan d‚Äôactions (Excel)", data=open(plan_path, "rb").read(), file_name=plan_path.name)
        st.download_button("‚¨áÔ∏è Rapport Word (complet)", data=open(docx_path, "rb").read(), file_name=docx_path.name)

        st.button("‚Ü©Ô∏è Revenir au questionnaire", key="anssi_results_back_to_questions", on_click=lambda: st.session_state.update({"anssi_stage":"questions"}) or st.rerun())
        st.button("‚¨ÖÔ∏è Retour √† l‚Äôaccueil", key="anssi_results_home", on_click=lambda: go("home"))
        return

# =========================================================
#            ISO 27001 (page & IA pr√©remplissage)
# =========================================================
def _ai_prefill_iso_by_domain(documents_text: str, iso_questions: Dict[str, List[Dict]]) -> Dict[str, Dict[str, str]]:
    client = get_openai_client()
    if client is None:
        return {}
    out: Dict[str, Dict[str, str]] = {}
    for domain, qs in iso_questions.items():
        q_list = []
        for q in qs:
            clause = q.get("clause", "")
            qtxt = q["question"]
            q_list.append({"clause": clause, "question": qtxt})
        ctx = documents_text[:16000]
        system = (
            "Tu es auditeur ISO/IEC 27001. "
            "Sur la base du contexte fourni, propose une r√©ponse courte (2-4 lignes) et factuelle pour chaque question. "
            "N'invente pas si l'info n'existe pas; mets 'Information insuffisante'. "
            "Renvoie STRICTEMENT du JSON: {\"answers\": [{\"question\": \"...\", \"answer\": \"...\"}, ...]}"
        )
        user = f"DOMAINE: {domain}\nQUESTIONS: {json.dumps(q_list, ensure_ascii=False)}\n\nCONTEXTE:\n{ctx}"
        try:
            resp = client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                messages=[{"role": "system", "content": system},
                          {"role": "user", "content": user}],
                temperature=0.2
            )
            content = (resp.choices[0].message.content or "").strip()
            data = json.loads(content)
            answers = data.get("answers", [])
        except Exception:
            answers = []
        out[domain] = {}
        for a in answers:
            qtxt = a.get("question", "")
            ans  = a.get("answer", "")
            if qtxt:
                out[domain][qtxt] = ans
    return out

def _mk_bullets(items: List[str]) -> str:
    return "\n".join([f"- {it}" for it in items])

def _to_question_fr(exigence: str, theme: Optional[str] = None) -> str:
    """Transforme une exigence ANSSI en question pro et actionnable."""
    if not exigence:
        return ""
    txt = exigence.strip()
    low = txt.lower()

    def block(title: str, bullets: List[str]) -> str:
        return f"**{title}**\n\nPoints attendus :\n{_mk_bullets(bullets)}"

    if any(k in low for k in ["sauvegard", "backup", "restaur"]):
        return block(
            "Comment l‚Äôorganisation assure les sauvegardes et la restauration ?",
            ["P√©rim√®tre (serveurs/postes/bases/Cloud)", "Fr√©quence & r√©tention (3-2-1)", "Chiffrement & gestion des cl√©s", "Tests de restauration (RPO/RTO)", "Supervision & PRA/PCA"]
        )
    # ‚Ä¶ (raccourci : autres heuristiques couvertes plus haut, conserv√©es)

    return block(
        f"Comment l‚Äôorganisation adresse l‚Äôexigence suivante : ¬´ {txt} ¬ª ?",
        ["Gouvernance", "Processus (SLA/approbations)", "Contr√¥les techniques", "Indicateurs & supervision", "Preuves (docs, logs, tickets)"]
    )

def render_iso27001():
    st.title("üîç Audit ISO 27001")
    # Uploader global utilisable aussi c√¥t√© ISO
    render_global_uploader()

    mode = st.radio(
        "üéØ Objectif d'audit",
        ["Audit interne", "Audit officiel / Pr√©-certification"],
        horizontal=True,
        index=0 if st.session_state.get("audit_mode", "interne") == "interne" else 1,
        key="audit_mode_choice",
    )
    st.session_state.audit_mode = "interne" if mode == "Audit interne" else "officiel"
    audit_mode = st.session_state.audit_mode

    ISO_QUESTIONS = ISO_QUESTIONS_INTERNE if audit_mode == "interne" else {**ISO_QUESTIONS_MANAGEMENT, **ISO_QUESTIONS_INTERNE}

    client_name_input = st.text_input(
        "üè¢ Nom du client pour cet audit",
        placeholder="Exemple : D&A, CACEIS, Banque XYZ...",
        key="client_name",
    ).strip()

    if client_name_input:
        st.success(f"Client s√©lectionn√© : **{client_name_input}**")
    else:
        st.info("‚û°Ô∏è Indiquez le nom du client pour activer l‚Äôimport des documents.")
        st.button("‚¨ÖÔ∏è Retour √† l‚Äôaccueil", key="iso_back_home", on_click=lambda: go("home"))
        st.stop()

    def extract_text_from_pdf(file):
        text = ""
        pdf = fitz.open(stream=file.read(), filetype="pdf")
        for page in pdf:
            text += page.get_text()
        return text

    def extract_text_from_docx(file):
        d = docx.Document(file)
        return "\n".join(p.text for p in d.paragraphs)

    def detect_client_name_with_ai(text):
        preview_text = text[:1500]
        prompt = f"""
Tu es un expert en audit ISO 27001.
Voici un extrait du d√©but d'un document d'audit :
---
{preview_text}
---
√Ä partir de cet extrait, identifie uniquement le NOM de l'organisation ou du client.
IMPORTANT :
- Ne donne pas d'explication.
- Ne r√©ponds que par le nom d√©tect√©.
- Si tu n'es pas s√ªr, r√©ponds exactement "Inconnu".
"""
        client = get_openai_client()
        if client is None:
            return "Inconnu"
        try:
            response = client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                messages=[{"role": "user", "content": prompt}],
                temperature=0
            )
            return (response.choices[0].message.content or "").strip()
        except Exception:
            return "Inconnu"

    def make_example_txt():
        content = (
            "Client: ACME BANK\n"
            "Document: ISMS Policy v1.2\n"
            "Scope: HQ + DataCenter\n"
            "Summary: High-level information security policy aligned to ISO/IEC 27001.\n"
        )
        return content.encode("utf-8")

    def make_example_docx():
        d = docx.Document()
        d.add_heading("Access Control Procedure", level=1)
        d.add_paragraph("Client: ACME BANK")
        d.add_paragraph("Purpose: Define access control rules aligned with ISO/IEC 27001 A.9.")
        d.add_paragraph("Scope: Corporate systems, VDI, privileged accounts, third parties.")
        bio = BytesIO()
        d.save(bio)
        bio.seek(0)
        return bio.getvalue()

    def make_correct_example_docx(client_name: str):
        d = docx.Document()
        d.add_heading("Exemple - Proc√©dure S√©curit√©", level=1)
        d.add_paragraph(f"Client: {client_name}")
        d.add_paragraph("Document type: Politique de s√©curit√© de l'information.")
        d.add_paragraph("Align√© avec ISO/IEC 27001 (contr√¥les A.5 √† A.18).")
        bio = BytesIO()
        d.save(bio)
        bio.seek(0)
        return bio.getvalue()

    st.subheader("üìÇ Importer documents du client (sp√©cifique √† ISO)")
    st.markdown(
        "Analysez vos documents (**politiques, proc√©dures, rapports**) pour pr√©-remplir le questionnaire, "
        "g√©n√©rez une **Gap Analysis** et un **rapport Word** pr√™t √† partager."
    )

    with st.expander("üìé Exemples de documents √† tester (t√©l√©chargeables)"):
        col_a, col_b = st.columns(2)
        with col_a:
            st.download_button(
                "‚¨áÔ∏è T√©l√©charger un exemple TXT",
                data=make_example_txt(),
                file_name="exemple_client.txt",
                mime="text/plain",
                use_container_width=True,
                key="iso_example_txt"
            )
        with col_b:
            st.download_button(
                "‚¨áÔ∏è T√©l√©charger un exemple DOCX",
                data=make_example_docx(),
                file_name="exemple_procedure.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                use_container_width=True,
                key="iso_example_docx"
            )

    uploaded_files = st.file_uploader(
        "Formats accept√©s : PDF, DOCX, TXT ‚Äî limite 200 Mo par fichier.",
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True,
        key="iso_uploader"
    )

    # On combine textes des uploads ISO + uploader global
    documents_text = get_uploaded_docs_text()
    detected_client_names = set()

    # Ajoute le texte des fichiers upload√©s ici (sp√©cifique ISO)
    if uploaded_files:
        for file in uploaded_files:
            if file.name.lower().endswith(".pdf"):
                text = extract_text_from_pdf(file)
            elif file.name.lower().endswith(".docx"):
                text = extract_text_from_docx(file)
            elif file.name.lower().endswith(".txt"):
                text = file.read().decode("utf-8", errors="ignore")
            else:
                text = ""
            documents_text += "\n" + text

            detected_name = detect_client_name_with_ai(text)
            if detected_name and detected_name != "Inconnu":
                detected_client_names.add(detected_name)

        if len(detected_client_names) > 1:
            st.error(
                f"‚ö†Ô∏è Plusieurs clients d√©tect√©s dans les documents : "
                f"{', '.join(detected_client_names)}"
            )
            st.stop()

        mismatch = detected_client_names and not any(
            client_name_input.lower() in name.lower() for name in detected_client_names
        )
        if mismatch:
            st.error(
                "üö® Incoh√©rence d√©tect√©e : "
                f"documents analys√©s pour {', '.join(detected_client_names)}, "
                f"‚â† nom saisi '{client_name_input}'.\n"
                "Veuillez corriger le nom ou importer les bons documents."
            )
            st.download_button(
                f"‚¨áÔ∏è T√©l√©charger un exemple DOCX pour {client_name_input}",
                data=make_correct_example_docx(client_name_input),
                file_name=f"exemple_{client_name_input.replace(' ', '_')}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                key="iso_example_correct_docx"
            )
            st.stop()

    responses = {}
    if documents_text.strip():
        client = get_openai_client()
        if client is None:
            st.warning("‚ÑπÔ∏è Aucune cl√© OpenAI d√©tect√©e ‚Äî l‚Äôanalyse IA des documents est d√©sactiv√©e.")
        else:
            st.info("üì° Analyse IA en cours...")
            responses = _ai_prefill_iso_by_domain(documents_text, ISO_QUESTIONS)
            st.success("‚úÖ Questionnaire pr√©-rempli par l'IA.")

    if responses:
        gap_analysis = analyse_responses(responses, nom_client=client_name_input)
        save_gap_analysis(gap_analysis, nom_client=client_name_input)

        df_gap = pd.DataFrame(gap_analysis)

        if not df_gap.empty:
            st.subheader("üìä Gap Analysis (vue interactive)")
            domaines = ["Tous"] + sorted(df_gap["Domaine ISO 27001"].unique())
            priorites = ["Toutes"] + sorted(df_gap["Priorit√©"].unique())

            col1, col2 = st.columns(2)
            with col1:
                filtre_domaine = st.selectbox("üìå Filtrer par domaine", domaines, key="iso_filter_domain")
            with col2:
                filtre_priorite = st.selectbox("‚ö° Filtrer par priorit√©", priorites, key="iso_filter_priority")

            df_filtre = df_gap.copy()
            if filtre_domaine != "Tous":
                df_filtre = df_filtre[df_filtre["Domaine ISO 27001"] == filtre_domaine]
            if filtre_priorite != "Toutes":
                df_filtre = df_filtre[df_filtre["Priorit√©"] == filtre_priorite]

            st.dataframe(df_filtre, use_container_width=True)

            export_gap = OUTPUT_DIR / "gap_analysis_ui.xlsx"
            df_filtre.to_excel(export_gap, index=False)
            st.download_button(
                "üì• T√©l√©charger Gap Analysis (Excel)",
                data=open(export_gap, "rb").read(),
                file_name="gap_analysis.xlsx",
                key="iso_export_gap"
            )

            if not df_filtre.empty:
                statut_counts = df_filtre["Statut"].value_counts().reset_index()
                statut_counts.columns = ["Statut", "Nombre"]

                color_map = {
                    "Conforme": "#2ecc71",
                    "‚úÖ Conforme": "#2ecc71",
                    "Non conforme": "#e74c3c",
                    "‚ùå Non conforme": "#e74c3c"
                }

                fig = px.pie(
                    statut_counts,
                    values="Nombre",
                    names="Statut",
                    title="R√©partition par statut de conformit√© (selon filtre)",
                    color="Statut",
                    color_discrete_map=color_map
                )
                st.plotly_chart(fig, use_container_width=True)

    # Formulaire interactif final
    with st.form("audit_form"):
        final_responses = {}
        for domain, questions in ISO_QUESTIONS.items():
            st.subheader(f"üìå {domain}")
            final_responses[domain] = {}
            for q in questions:
                clause = q.get("clause", "")
                question_text = q["question"]
                question_display = f"{clause} ‚Äì {question_text}" if clause else question_text
                answer_data = responses.get(domain, {}).get(question_text, "")

                key_suffix = f"{domain}_{clause}_{hash(question_text)}"

                if isinstance(answer_data, dict):
                    reponse_simple = answer_data.get("R√©ponse", "")
                    new_answer = st.text_area(
                        question_display,
                        value=reponse_simple,
                        key=f"ta_{key_suffix}"
                    )
                    final_responses[domain][question_text] = {**answer_data, "R√©ponse": new_answer}
                else:
                    new_answer = st.text_area(
                        question_display,
                        value=answer_data,
                        key=f"tb_{key_suffix}"
                    )
                    final_responses[domain][question_text] = new_answer

        submitted = st.form_submit_button("üì• G√©n√©rer l'analyse et le rapport")  # <‚Äî pas de 'key' ici

    if submitted:
        gap_analysis = analyse_responses(final_responses, nom_client=client_name_input)
        save_gap_analysis(gap_analysis, nom_client=client_name_input)

        report_path = generate_audit_report()

        st.success("‚úÖ Rapport g√©n√©r√© avec succ√®s !")
        st.download_button(
            "üìÑ T√©l√©charger rapport Word",
            data=open(report_path, "rb").read(),
            file_name=Path(report_path).name,
            key="iso_download_report"
        )
        st.download_button(
            "üìä T√©l√©charger Gap Analysis",
            data=open(OUTPUT_DIR / "gap_analysis.xlsx", "rb").read(),
            file_name="gap_analysis.xlsx",
            key="iso_download_gap"
        )

        action_client = get_openai_client()
        if action_client is None:
            st.warning("‚ÑπÔ∏è Pas de cl√© OpenAI ‚Äî g√©n√©ration automatique du plan d‚Äôactions d√©sactiv√©e.")
        else:
            action_plan = generate_action_plan_from_ai(gap_analysis, nom_client=client_name_input)
            save_action_plan_to_excel(action_plan)

            st.subheader("üìÖ Plan d‚Äôactions recommand√©")
            df_plan = pd.DataFrame(action_plan)
            if not df_plan.empty:
                st.dataframe(df_plan, use_container_width=True)
                st.download_button(
                    "üì• T√©l√©charger le plan d‚Äôactions (Excel)",
                    data=open(OUTPUT_DIR / "action_plan.xlsx", "rb").read(),
                    file_name="plan_actions.xlsx",
                    key="iso_download_plan"
                )
            else:
                st.info("‚úÖ Aucun plan d‚Äôaction n√©cessaire, tout est conforme.")

    st.divider()
    st.button("‚¨ÖÔ∏è Retour √† l‚Äôaccueil", key="iso_home", on_click=lambda: go("home"))

# =========================================================
#                       DISPATCH
# =========================================================
page = st.session_state.get("route", "home")

if page == "home":
    render_home()
elif page == "anssi_hygiene":
    render_anssi_hygiene()
elif page == "iso27001":
    render_iso27001()
else:
    st.session_state["route"] = "home"
    render_home()